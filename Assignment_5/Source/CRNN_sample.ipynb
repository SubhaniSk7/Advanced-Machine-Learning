{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import Dataset,DataLoader,SequentialSampler,SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cv2,os, warnings,joblib\n",
    "from skimage import io,transform\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CRNN model\n",
    "    Args:\n",
    "        in_channels (int): input channel number，1 for grayscaled images，3 for rgb images\n",
    "        out_channels (int): output channel number(class number), letters number in dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        hidden_size = 256\n",
    "        # CNN struct and parameters\n",
    "        self.cnn_struct = ((64, ), (128, ), (256, 256), (512, 512), (512, ))\n",
    "        self.cnn_paras = ((3, 1, 1), (3, 1, 1),\n",
    "                          (3, 1, 1), (3, 1, 1), (2, 1, 0))\n",
    "        # pooling layer struct\n",
    "        self.pool_struct = ((2, 2), (2, 2), (2, 1), (2, 1), None)\n",
    "        # add batchnorm layer or not\n",
    "        self.batchnorm = (False, False, False, True, False)\n",
    "        self.cnn = self._get_cnn_layers()\n",
    "        # output channel number of LSTM in pytorch is hidden_size *\n",
    "        #     num_directions, num_directions=2 for bidirectional LSTM\n",
    "        self.rnn1 = nn.LSTM(self.cnn_struct[-1][-1],\n",
    "                            hidden_size, bidirectional=True)\n",
    "        self.rnn2 = nn.LSTM(hidden_size*2, hidden_size, bidirectional=True)\n",
    "        # fully-connected\n",
    "        self.fc = nn.Linear(hidden_size*2, out_channels)\n",
    "\n",
    "    def forward(self, x):   # input: height=32, width>=100\n",
    "        x = self.cnn(x)   # batch, channel=512, height=1, width>=24\n",
    "        x = x.squeeze(2)   # batch, channel=512, width>=24\n",
    "        x = x.permute(2, 0, 1)   # width>=24, batch, channel=512\n",
    "        x = self.rnn1(x)[0]   # length=width>=24, batch, channel=256*2\n",
    "        x = self.rnn2(x)[0]   # length=width>=24, batch, channel=256*2\n",
    "        l, b, h = x.size()\n",
    "        x = x.view(l*b, h)   # length*batch, hidden_size*2\n",
    "        x = self.fc(x)   # length*batch, output_size\n",
    "        x = x.view(l, b, -1)   # length>=24, batch, output_size\n",
    "        return x\n",
    "\n",
    "    def _get_cnn_layers(self):\n",
    "        cnn_layers = []\n",
    "        in_channels = self.in_channels\n",
    "        for i in range(len(self.cnn_struct)):\n",
    "            for out_channels in self.cnn_struct[i]:\n",
    "                cnn_layers.append(\n",
    "                    nn.Conv2d(in_channels, out_channels, *(self.cnn_paras[i])))\n",
    "                if self.batchnorm[i]:\n",
    "                    cnn_layers.append(nn.BatchNorm2d(out_channels))\n",
    "                cnn_layers.append(nn.ReLU(inplace=True))\n",
    "                in_channels = out_channels\n",
    "            if (self.pool_struct[i]):\n",
    "                cnn_layers.append(nn.MaxPool2d(self.pool_struct[i]))\n",
    "        return nn.Sequential(*cnn_layers)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (18): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "  )\n",
       "  (rnn1): LSTM(512, 256, bidirectional=True)\n",
       "  (rnn2): LSTM(512, 256, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=36, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = CRNN(1, 36)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
