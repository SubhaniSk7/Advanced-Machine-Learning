{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import Dataset,DataLoader,SequentialSampler,SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cv2,os, warnings,joblib\n",
    "from skimage import io,transform\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IIITDataset(Dataset):\n",
    "    def __init__(self, csv_filename, image_dir, transform=None):\n",
    "        self.dataset = pd.read_csv(csv_filename)\n",
    "        self.root_dir = image_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        if(torch.is_tensor(index)):\n",
    "            index = index.tolist()\n",
    "        label = self.dataset.iloc[index,1] # here label column = 1\n",
    "        \n",
    "        image_name = self.dataset.iloc[index,0] #here image path column=0\n",
    "        path = os.path.join(self.root_dir,image_name)\n",
    "        image = Image.open(path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "class LabelTransformer(object):\n",
    "    \"\"\"\n",
    "    encoder and decoder\n",
    "    Args:\n",
    "        letters (str): Letters contained in the data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, letters):\n",
    "        self.encode_map = {letter: idx+1 for idx, letter in enumerate(letters)}\n",
    "        self.decode_map = ' ' + letters\n",
    "\n",
    "    def encode(self, text):\n",
    "        if isinstance(text, str):\n",
    "            length = [len(text)]\n",
    "            result = [self.encode_map[letter] for letter in text]\n",
    "        else:\n",
    "            length = []\n",
    "            result = []\n",
    "            for word in text:\n",
    "                length.append(len(word))\n",
    "                result.extend([self.encode_map[letter] for letter in word])\n",
    "        return torch.IntTensor(result), torch.IntTensor(length)\n",
    "\n",
    "    def decode(self, text_code):\n",
    "        result = []\n",
    "        for code in text_code:\n",
    "#             print(':',code,':')\n",
    "            word = []\n",
    "            for i in range(len(code)):\n",
    "                if code[i] != 0 and (i == 0 or code[i] != code[i-1]):\n",
    "                    word.append(self.decode_map[code[i]])\n",
    "            result.append(''.join(word))\n",
    "#         print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"E:\\Sem3\\AML\\Assignments & Quiz\\Assignment_5\\Dataset\\IIIT5K-Word_V3.0\\IIIT5K\"\n",
    "test_path = r\"E:\\Sem3\\AML\\Assignments & Quiz\\Assignment_5\\Dataset\\IIIT5K-Word_V3.0\\IIIT5K\"\n",
    "\n",
    "# train_path = r\"IIIT5K\"\n",
    "# test_path = r\"IIIT5K\"\n",
    "\n",
    "device='cuda'\n",
    "# device = 'cpu'\n",
    "n_workers = 0\n",
    "batch_size = 10\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                transforms.Resize((32,100),Image.BICUBIC),\n",
    "                                transforms.Grayscale(),\n",
    "                                transforms.ToTensor()\n",
    "                               ])\n",
    "\n",
    "train_data = IIITDataset(csv_filename=\"train.csv\",image_dir=train_path,transform=transform)\n",
    "test_data = IIITDataset(csv_filename=\"test.csv\",image_dir=test_path,transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=n_workers)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Architecture(nn.Module):\n",
    "    def __init__(self, in_channels, out_size):\n",
    "        super(Architecture,self).__init__()\n",
    "        \n",
    "        hidden_size = 256\n",
    "        self.conv_1 = nn.Conv2d(in_channels, 64, 3 ,padding=1, stride=1)\n",
    "        self.pool_1 = nn.MaxPool2d((2,2),stride=(2,2))\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(64, 128, 3 ,padding=1, stride=1)\n",
    "        self.pool_2 = nn.MaxPool2d((2,2),stride=(2,2))\n",
    "        \n",
    "        self.conv_3 = nn.Conv2d(128, 256, 3 ,padding=1, stride=1)\n",
    "        self.conv_4 = nn.Conv2d(256, 256, 3 ,padding=1, stride=1)\n",
    "        self.pool_3 = nn.MaxPool2d((2,1),stride=(2,1))\n",
    "        \n",
    "        self.conv_5 = nn.Conv2d(256, 512, 3 ,padding=1, stride=1)\n",
    "        self.b_1 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv_6 = nn.Conv2d(512, 512, 3 ,padding=1, stride=1)\n",
    "        self.b_2 = nn.BatchNorm2d(512)\n",
    "        self.pool_4 = nn.MaxPool2d((2,1),stride=(2,1))\n",
    "        \n",
    "        self.conv_7 = nn.Conv2d(512, 512, 2 ,padding=0, stride=1)\n",
    "        \n",
    "        self.L_1 = nn.LSTM(input_size = 512, hidden_size = hidden_size, bidirectional=True) \n",
    "        self.L_2 = nn.LSTM(input_size = hidden_size*2, hidden_size = 256, bidirectional=True)# input = inputsize*direction\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size*2,out_size)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        x = self.relu(self.conv_1(x))\n",
    "#         print('conv_1:',x.shape)\n",
    "        x = self.pool_1(x)\n",
    "#         print('pool_1:',x.shape)\n",
    "        x = self.relu(self.conv_2(x))\n",
    "#         print('conv_2:',x.shape)\n",
    "        x = self.pool_2(x)\n",
    "#         print('pool_2:',x.shape)\n",
    "        x = self.relu(self.conv_3(x))\n",
    "#         print('conv_3:',x.shape)\n",
    "        x = self.relu(self.conv_4(x))\n",
    "#         print('conv_4:',x.shape)\n",
    "        x = self.pool_3(x)\n",
    "#         print('pool_3:',x.shape)\n",
    "        x = self.relu(self.conv_5(x))\n",
    "#         print('conv_5:',x.shape)\n",
    "        x = self.b_1(x)\n",
    "#         print('b_1:',x.shape)\n",
    "        x = self.relu(self.conv_6(x))\n",
    "#         print('conv_6:',x.shape)\n",
    "        x = self.b_2(x)\n",
    "#         print('b_2:',x.shape)\n",
    "        x = self.pool_4(x)\n",
    "#         print('pool_4:',x.shape)\n",
    "        \n",
    "        x = self.relu(self.conv_7(x))\n",
    "#         print('conv_7:',x.shape)\n",
    "    \n",
    "        x = x.squeeze(2)\n",
    "#         print('sq:',x.shape)\n",
    "        \n",
    "        x = x.permute(2, 0, 1)\n",
    "#         print('permute:',x.shape)\n",
    "        \n",
    "        results = self.L_1(x)\n",
    "        out, hidden = results[0], results[1]\n",
    "#         print('L_1:',out.shape,hidden[0].shape, hidden[1].shape)\n",
    "        \n",
    "        results = self.L_2(out)\n",
    "        out, hidden = results[0], results[1]\n",
    "#         print('L_2:',out.shape,hidden[0].shape, hidden[1].shape)\n",
    "        \n",
    "        x = out\n",
    "        \n",
    "        l, b, h = x.size()\n",
    "#         print('width,batch,height(channels):',l,b,h)\n",
    "        \n",
    "        x = x.view(l*b,h) # length*batch, hidden_size*2\n",
    "#         print('view:',x.shape)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "#         print('fc:',x.shape)\n",
    "        \n",
    "        x = x.view(l, b, -1)   # length>=24, batch, output_size\n",
    "#         print('view:',x.shape)\n",
    "        return x\n",
    "    \n",
    "\n",
    "letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "model = Architecture(1,len(letters) + 1)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CTCLoss()\n",
    "criterion.to(device)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelTransformer.decode_map\n",
    "\n",
    "# labelTransformer.encode_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([25, 15, 21, 18,  5, 19,  3, 21,  5, 13,  9, 19, 19,  9, 15, 14,  8, 15,\n",
      "        13,  5,  2, 15, 18,  4,  5, 18,  4, 15,  4,  1,  2,  1, 20, 15, 20,  5,\n",
      "        28, 31, 30, 11, 13, 28, 36, 30, 11, 13, 30, 28, 32, 11, 13],\n",
      "       dtype=torch.int32) tensor([3, 6, 7, 4, 6, 4, 6, 5, 5, 5], dtype=torch.int32) tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24], device='cuda:0')\n",
      "tensor([16, 12,  5,  1, 19,  5, 18, 15,  1,  4, 19, 15, 18,  7,  1, 14,  9, 19,\n",
      "         1, 20,  9, 15, 14, 23,  9, 19,  8,  5, 19,  3,  8,  9, 14,  7,  1, 13,\n",
      "        11,  9, 19,  8, 20, 23,  1, 18, 11, 21, 13,  1, 18,  3,  1, 18,  4, 31,\n",
      "        30, 34, 34, 27, 28, 29, 30], dtype=torch.int32) tensor([ 6,  5, 12,  6,  7,  8,  5,  4,  4,  4], dtype=torch.int32) tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24], device='cuda:0')\n",
      "tensor([15,  6,  9, 14,  4,  9,  1, 19, 20,  1, 20,  5,  9, 14,  4,  9,  1, 19,\n",
      "         1, 22,  5, 20,  8,  5, 12, 15, 19,  5, 15,  6,  9, 14,  4,  9,  1, 19,\n",
      "         1, 10,  9, 20,  8], dtype=torch.int32) tensor([2, 5, 5, 5, 4, 3, 4, 2, 5, 6], dtype=torch.int32) tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24], device='cuda:0')\n",
      "tensor([ 5, 18,  1, 20, 20, 21, 16,  5, 20, 20,  1,  1, 16,  1, 18, 20, 14,  5,\n",
      "        18,  6, 15, 18, 12,  9,  6,  5,  9, 14,  4,  9,  1, 19, 20,  1, 20,  5,\n",
      "         2,  1, 14, 11, 15,  6, 15,  6], dtype=torch.int32) tensor([11,  1,  7,  3,  4,  5,  5,  4,  2,  2], dtype=torch.int32) tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24], device='cuda:0')\n",
      "tensor([ 9, 14,  4,  9,  1,  3,  8,  1, 18, 20, 19,  2, 25,  2,  1, 14, 11, 15,\n",
      "         6,  9, 14,  4,  9,  1,  3,  8,  1, 18, 20, 19, 19, 20,  1, 20,  5,  2,\n",
      "         1, 14, 11, 15,  6], dtype=torch.int32) tensor([5, 6, 2, 4, 2, 5, 6, 5, 4, 2], dtype=torch.int32) tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24], device='cuda:0')\n",
      "tensor([ 9, 14,  4,  9,  1, 23, 23, 23, 20, 15, 16, 19, 20, 15,  3, 11, 18,  5,\n",
      "        19,  5,  1, 18,  3,  8,  3, 15, 13,  9, 16,  1,  4,  3, 16, 13, 28, 27,\n",
      "        29, 32, 31, 32, 31, 29, 29, 33, 28, 32, 27,  3, 15, 13, 16,  1, 18,  9,\n",
      "        19, 15, 14, 28, 29, 27, 27], dtype=torch.int32) tensor([ 5, 22,  4,  3,  4,  3,  3,  3, 10,  4], dtype=torch.int32) tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24], device='cuda:0')\n",
      "tensor([31, 27, 27, 29, 27, 27, 27, 27, 27,  4, 15,  5, 19,  4,  9, 18,  5,  3,\n",
      "        20,  9, 15, 14, 14, 15, 20,  9,  3,  5,  4, 13, 28, 36, 34,  1, 16, 16,\n",
      "        12,  5,  3,  5, 14, 20,  5, 18], dtype=torch.int32) tensor([3, 3, 3, 4, 9, 7, 1, 3, 5, 6], dtype=torch.int32) tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24], device='cuda:0')\n",
      "tensor([15, 18,  7,  1, 14,  9,  3,  9, 14, 20,  5, 18, 14,  5, 20, 19,  9, 14,\n",
      "         7,  1, 16, 15, 18,  5, 12,  9, 22,  5,  3, 18,  5,  1, 20,  9, 14,  7,\n",
      "        25, 15, 21, 18,  4, 18,  5,  1, 13, 19, 13,  9, 12,  5, 25, 15, 21, 22,\n",
      "         5, 20,  8,  1, 20], dtype=torch.int32) tensor([7, 8, 9, 4, 8, 4, 5, 5, 5, 4], dtype=torch.int32) tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24], device='cuda:0')\n",
      "tensor([ 4, 18,  5, 19, 19, 20,  8,  5, 13, 14, 15, 23, 20, 21, 18, 14, 12,  5,\n",
      "         6, 20,  1, 12, 23,  1, 25, 19, 19,  1,  9,  4, 25, 15, 21,  4,  5,  1,\n",
      "         4,  9, 14], dtype=torch.int32) tensor([5, 4, 3, 4, 4, 6, 4, 3, 4, 2], dtype=torch.int32) tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b3124180afbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mlabel_length\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0moutput_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-b5f8b938c1ee>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;31m#         print('L_1:',out.shape,hidden[0].shape, hidden[1].shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m#         print('L_2:',out.shape,hidden[0].shape, hidden[1].shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[1;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[1;32m--> 526\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labelTransformer = LabelTransformer(letters)\n",
    "train_loss_plt, valid_loss_plt = [], []\n",
    "test_accuracy_plt = []\n",
    "test_loss_plt = []\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, test_loss = 0, 0\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images = images.to(device)\n",
    "        label, label_length = labelTransformer.encode(labels)\n",
    "        \n",
    "        label.to(device)\n",
    "        label_length.to(device)\n",
    "        \n",
    "        output = model(images)\n",
    "        output_length = torch.tensor([output.size(0)]*output.size(1)).to(device)\n",
    "        \n",
    "#         print(label, label_length, output_length)\n",
    "        loss = criterion(output, label, output_length, label_length)\n",
    "        \n",
    "        result = output.max(2)[1].transpose(0, 1)  # batch × length\n",
    "        result = labelTransformer.decode(result.data)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    \n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_loss_plt.append(train_loss)\n",
    "    print('Epoch:', (epoch + 1), '\\tTrain Loss:', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
