{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block is taken from my previous work\n",
    "class Layer:\n",
    "    # constructor\n",
    "    def __init__(self, neurons=0, theta=[], b=[], z=[], a=[],delta=[],DELTA_THETA=[],DELTA_BIAS=[],dTheta=[],dBias=[]):\n",
    "        self.neurons = 0 # neurons count in layer\n",
    "        self.theta = [] # Weight vector(W)\n",
    "        self.b=[] # bias\n",
    "        self.z = [] # hypothesis z = W.T * X + b = here = theta.T * X + b\n",
    "        self.a = [] # activation function a=sigmoid(z) or relu(z) or anyother(z)\n",
    "        self.delta = [] # Loss or Error function delta= delta_cross_entropy() or anyother()\n",
    "        self.DELTA_THETA = [] # only derivative weight vector =dw\n",
    "        self.DELTA_BIAS = [] # only derivative bias vector =db\n",
    "        self.dTheta = [] # complete derivation term = (1/m)*(DELTA + (lambda*theta))\n",
    "        self.dBias = [] # complete derivation term \n",
    "\n",
    "    def setNeurons(self, neurons):\n",
    "        self.neurons = neurons\n",
    "\n",
    "    def getNeurons(self):\n",
    "        return self.neurons\n",
    "\n",
    "    def setTheta(self, theta):\n",
    "        self.theta = theta\n",
    "\n",
    "    def getTheta(self):\n",
    "        return self.theta\n",
    "\n",
    "    def setB(self, b):\n",
    "        self.b = b\n",
    "\n",
    "    def getB(self):\n",
    "        return self.b\n",
    "\n",
    "    def setZ(self, z):\n",
    "        self.z = z\n",
    "\n",
    "    def getZ(self):\n",
    "        return self.z\n",
    "\n",
    "    def setA(self, a):\n",
    "        self.a = a\n",
    "\n",
    "    def getA(self):\n",
    "        return self.a\n",
    "\n",
    "    def setDelta(self, delta):\n",
    "        self.delta = delta\n",
    "\n",
    "    def getDelta(self):\n",
    "        return self.delta\n",
    "\n",
    "    def setDELTA_THETA(self, DELTA_THETA):\n",
    "        self.DELTA_THETA = DELTA_THETA\n",
    "\n",
    "    def getDELTA_THETA(self):\n",
    "        return self.DELTA_THETA\n",
    "\n",
    "    def setDELTA_BIAS(self, DELTA_BIAS):\n",
    "        self.DELTA_BIAS = DELTA_BIAS\n",
    "\n",
    "    def getDELTA_BIAS(self):\n",
    "        return self.DELTA_BIAS\n",
    "    \n",
    "    def setDTheta(self, dTheta):\n",
    "        self.dTheta = dTheta\n",
    "\n",
    "    def getDTheta(self):\n",
    "        return self.dTheta\n",
    "    \n",
    "    def setDBias(self, dBias):\n",
    "        self.dBias = dBias\n",
    "\n",
    "    def getDBias(self):\n",
    "        return self.dBias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = [[252,4,155,175],[175,10,186,200],[82,131,230,100],[115,138,80,88]]\n",
    "data_Y = [1,1,0,0]\n",
    "X,Y = np.array(data_X),np.array(data_Y)\n",
    "\n",
    "y_actual=[] # changed to 1 at their index\n",
    "for i in range(Y.shape[0]):\n",
    "    temp = [0]*2\n",
    "    index = int(Y[i])\n",
    "    temp[index] = 1\n",
    "    y_actual.append(temp)\n",
    "y_actual=np.array(y_actual).T\n",
    "\n",
    "m=X.shape[0] # no.of samples\n",
    "X=X.T # transposed X now shape=4x4 => now each column is one datapoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1.0/(1.0+np.exp(-z)))\n",
    "\n",
    "def softmax(z):\n",
    "    return np.divide(np.exp(z),np.sum(np.exp(z),axis=0))\n",
    "\n",
    "def delta_cross_entropy(z,y):\n",
    "    return (z-y)/m\n",
    "\n",
    "def accuracy(y_predicted):\n",
    "    y_multilabel = []\n",
    "    for p in y_predicted:\n",
    "        y_multilabel.append(list(p).index(max(p)))\n",
    "    print(accuracy_score(y_multilabel, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 --> 0.5\n",
      "[[-0.00031629  0.00831931]\n",
      " [-0.00053876  0.00384176]\n",
      " [ 0.00902096  0.00246989]\n",
      " [-0.00404164 -0.00925572]]\n",
      "[[-0.00468768]\n",
      " [ 0.00796985]]\n",
      "[[-0.00513489  0.00406489]\n",
      " [ 0.00403196 -0.00034196]]\n",
      "[[-0.00583413]\n",
      " [-0.00236587]]\n",
      "--------------------------\n",
      "Iteration: 1 --> 0.5\n",
      "[[ 0.00349452  0.00700832]\n",
      " [-0.00396855  0.00518983]\n",
      " [ 0.01052025  0.00218466]\n",
      " [-0.00077999 -0.01038409]]\n",
      "[[-0.0046839 ]\n",
      " [ 0.00796922]]\n",
      "[[-0.00360593  0.00253593]\n",
      " [ 0.00488004 -0.00119004]]\n",
      "[[-0.00574542]\n",
      " [-0.00245458]]\n",
      "--------------------------\n",
      "Iteration: 2 --> 0.5\n",
      "[[ 0.00729432  0.00454884]\n",
      " [-0.00822443  0.00758384]\n",
      " [ 0.01175489  0.00162382]\n",
      " [ 0.00247575 -0.01245456]]\n",
      "[[-0.00468334]\n",
      " [ 0.00796767]]\n",
      "[[-0.00294281  0.00187281]\n",
      " [ 0.00692844 -0.00323844]]\n",
      "[[-0.00562605]\n",
      " [-0.00257395]]\n",
      "--------------------------\n",
      "Iteration: 3 --> 0.75\n",
      "[[ 0.01075904  0.00086148]\n",
      " [-0.01305277  0.01187479]\n",
      " [ 0.01258291  0.00129984]\n",
      " [ 0.00545001 -0.01541357]]\n",
      "[[-0.00468647]\n",
      " [ 0.00796861]]\n",
      "[[-0.00332088  0.00225088]\n",
      " [ 0.01128316 -0.00759316]]\n",
      "[[-0.00548931]\n",
      " [-0.00271069]]\n",
      "--------------------------\n",
      "Iteration: 4 --> 1.0\n",
      "[[ 0.0137588  -0.00206002]\n",
      " [-0.01851448  0.01987386]\n",
      " [ 0.01289998  0.00381411]\n",
      " [ 0.00803224 -0.01742416]]\n",
      "[[-0.00469408]\n",
      " [ 0.00798848]]\n",
      "[[-0.00476561  0.00369561]\n",
      " [ 0.01890806 -0.01521806]]\n",
      "[[-0.00534445]\n",
      " [-0.00285555]]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "w=[[[-0.00256, 0.00889],[ 0.00146, 0.00322],[0.00816 ,0.00258],[ -0.00597, -0.00876]],\n",
    "  [[-0.00647 ,0.00540], [0.00374, -0.00005]]]\n",
    "\n",
    "b=[[[-0.00469],[0.00797]],[[-0.00588],[-0.00232]]]\n",
    "\n",
    "l, neurons=3, [4,2,2]\n",
    "layers=[]\n",
    "for i in range(len(neurons)):\n",
    "    lay=Layer()\n",
    "    if(i!=len(neurons)-1):\n",
    "        DELTA_THETA=np.zeros((neurons[i+1],neurons[i]))\n",
    "#         theta=np.random.uniform(low=0.1,high=1,size=(neurons[i],neurons[i+1]))\n",
    "        theta=np.array(w[i])\n",
    "        DELTA_BIAS=np.zeros((neurons[i+1],1))\n",
    "        bias=np.array(b[i])\n",
    "        lay.setDELTA_THETA(DELTA_THETA)\n",
    "        lay.setTheta(theta)\n",
    "        lay.setDELTA_BIAS(DELTA_BIAS)\n",
    "        lay.setB(bias)\n",
    "    layers.append(lay)\n",
    "layers[0].setA(X)\n",
    "\n",
    "regParam, alpha, maxIterations = 0, 0.1, 5\n",
    "for iter in range(maxIterations):\n",
    "    # Forward propagation\n",
    "    for i in range(1,l):\n",
    "        z=np.dot(layers[i-1].getTheta().T, layers[i-1].getA())\n",
    "        z=z+layers[i-1].getB()\n",
    "        if(i==l-1):\n",
    "            a=softmax(z)\n",
    "        else:\n",
    "            a=sigmoid(z)\n",
    "        layers[i].setZ(z)\n",
    "        layers[i].setA(a)\n",
    "        \n",
    "    # Backward Propagation\n",
    "    for i in range(l-1,-1,-1):\n",
    "        loss=None\n",
    "        if(i==l-1):\n",
    "            loss=delta_cross_entropy(layers[i].getA(),y_actual)\n",
    "        else:\n",
    "            loss=np.dot(layers[i].getTheta(),layers[i+1].getDelta()) * (layers[i].getA()*(1-layers[i].getA()))\n",
    "        layers[i].setDelta(loss)\n",
    "    \n",
    "    #weights\n",
    "    for i in range(0,l-1):\n",
    "        D=layers[i].getDELTA_THETA() + np.dot(layers[i+1].getDelta(),layers[i].getA().T)\n",
    "        layers[i].setDELTA_THETA(D)\n",
    "    \n",
    "    for i in range(0,l-1):\n",
    "        dT=(1/m)*(layers[i].getDELTA_THETA().T+(regParam*layers[i].getTheta()))\n",
    "        layers[i].setDTheta(dT)\n",
    "    \n",
    "    #bias\n",
    "    for i in range(0,l-1):\n",
    "#         B=layers[i].getDELTA_BIAS() + np.dot(layers[i+1].getDelta(),1)\n",
    "        B=layers[i].getDELTA_BIAS() + (layers[i+1].getDelta()).T.sum(0,keepdims=True).T\n",
    "        layers[i].setDELTA_BIAS(B)\n",
    "    \n",
    "    for i in range(0,l-1):\n",
    "        dB=(1/m)*(layers[i].getDELTA_BIAS()+(regParam*layers[i].getB()))\n",
    "        layers[i].setDBias(dB)\n",
    "    \n",
    "    print('Iteration:',iter,'--> ',end='')\n",
    "    if(accuracy(layers[-1].getA().T) == np.nan):\n",
    "        break\n",
    "        \n",
    "    \n",
    "    for i in range(0,l-1):\n",
    "        newTh=layers[i].getTheta()-(alpha*layers[i].getDTheta())\n",
    "        newBias=layers[i].getB()-(alpha*layers[i].getDBias())\n",
    "        layers[i].setTheta(newTh)\n",
    "        layers[i].setB(newBias)\n",
    "    \n",
    "    for j in range(len(layers)-1):\n",
    "        print(layers[j].getTheta())\n",
    "        print(layers[j].getB())\n",
    "    print('--------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0137588  -0.00206002]\n",
      " [-0.01851448  0.01987386]\n",
      " [ 0.01289998  0.00381411]\n",
      " [ 0.00803224 -0.01742416]]\n",
      "[[-0.00469408]\n",
      " [ 0.00798848]]\n",
      "[[-0.00476561  0.00369561]\n",
      " [ 0.01890806 -0.01521806]]\n",
      "[[-0.00534445]\n",
      " [-0.00285555]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(layers)-1):\n",
    "    print(layers[i].getTheta())\n",
    "    print(layers[i].getB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
